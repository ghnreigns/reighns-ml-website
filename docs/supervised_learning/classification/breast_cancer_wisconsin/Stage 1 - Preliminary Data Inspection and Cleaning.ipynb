{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3048b3ac-aba0-4378-99db-92e6f30e9d1f",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<a id = '1.0'></a>\n",
    "<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal;background-color: #2ab7ca; color : #fed766; border-radius: 5px 5px;padding:5px;text-align:center; font-weight: bold\" >Quick Navigation</h1>\n",
    "\n",
    "    \n",
    "* [Dependencies and Configuration](#1)\n",
    "* [Stage 1: Preliminary Data Inspection and Cleaning](#2)\n",
    "    * [Load the dataset](#31)\n",
    "    * [A brief look at the dataset](#31)\n",
    "    * [Drop, drop, drop the columns!](#31)\n",
    "    * [Data Types](#31)\n",
    "    * [Summary Statistics](#31)\n",
    "    * [Missing Data](#31)\n",
    "    * [Save Data](#31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02052cd-fd0e-46fa-92b0-5c754237b674",
   "metadata": {},
   "source": [
    "# Dependencies and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b2873bf-fc0f-4573-9f18-c89ff02c9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "208eba21-91f3-4384-ae71-1c568a43c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class global_config:\n",
    "    \n",
    "    # File Path\n",
    "    raw_data = \"../data/raw/data.csv\"\n",
    "    processed_data_stage_1 = \"../data/processed/data_stage_1.csv\"\n",
    "    processed_data_stage_2 = \"../data/processed/data_stage_2.csv\"\n",
    "    processed_data_stage_3 = \"../data/processed/data_stage_3.csv\"\n",
    "\n",
    "    # Data Information\n",
    "    target = [\"diagnosis\"]\n",
    "    unwanted_cols = [\"id\", \"Unnamed: 32\"]\n",
    "\n",
    "    # Plotting\n",
    "    colors = [\"#fe4a49\", \"#2ab7ca\", \"#fed766\", \"#59981A\"]\n",
    "    cmap_reversed = plt.cm.get_cmap('mako_r')\n",
    "    \n",
    "    # Seed Number\n",
    "    seed = 1992\n",
    "\n",
    "    # Cross Validation\n",
    "    num_folds = 5\n",
    "    cv_schema = \"StratifiedKFold\"\n",
    "    split_size = {\"train_size\": 0.9, \"test_size\": 0.1}\n",
    "\n",
    "\n",
    "def set_seeds(seed: int = 1234) -> None:\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d800713d-f3a9-45f0-a5b3-a11eb58646aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config\n",
    "config = global_config\n",
    "\n",
    "# set seeding for reproducibility\n",
    "_ = set_seeds(seed = config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f4183-e442-44d2-b05f-9b0c2e5fdfa8",
   "metadata": {},
   "source": [
    "# Stage 1: Preliminary Data Inspection and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c25acd-fe73-4a5d-b66a-255dc89b632c",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a98da4-94e1-481b-837e-9ed7b9f1e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950f293-de83-4287-af7b-5b27b3fd6850",
   "metadata": {},
   "source": [
    "## A brief look at the dataset\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<li> We will query the first five rows of the dataframe to get a feel on the dataset we are working on. \n",
    "    \n",
    "<li> We also call <code> df.info() </code> to see the data types of the columns, and to briefly check if there is any missing values in our data (more on that later). \n",
    "</div>\n",
    "\n",
    "```python\n",
    " #   Column                   Non-Null Count  Dtype  \n",
    "---  ------                   --------------  -----  \n",
    " 0   diagnosis                569 non-null    int64  \n",
    " 1   radius_mean              569 non-null    float64\n",
    " 2   texture_mean             569 non-null    float64\n",
    " 3   perimeter_mean           569 non-null    float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Importance of data types:</b> We must be sharp and ensure that each column is indeed stored in their respective data types! In the real world, we may often query \"dirty\" data from say, the database, where numeric data are represented in string. It is now our duty to ensure sanity checks are in place!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a61bfdd-baa3-4763-965a-974613e778cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())\n",
    "# display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a13b4d-01bb-44d6-8eeb-678099417e5c",
   "metadata": {},
   "source": [
    "A brief overview tells us our data is alright! There is, however, a column which is unnamed and has no values. This can be of various data source issues, for now, we quickly check the definition given by the dataset from [UCI's Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) and confirm that there should only be 32 columns. With this in mind, we can safely delete the column. \n",
    "\n",
    "---\n",
    "\n",
    "We also note that from the above, that the **id** column is the identifier for each patient. We will also drop this column as it holds no predictive power.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>When can ID be important?</b>\n",
    "<li> We should try to question our move and justify it. In this dataset, we have to ensure that each <b>ID</b> is unique, if it is not, it may suggest that there are patient records with multiple observation, which is a violation of <b>i.i.d</b> assumption and we may take note when doing cross-validation, so as to avoid information leakage.\n",
    "<li> Since the ID column is unique, we will delete it. We will keep this at the back of our mind in the event that we ever need them for feature engineering.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051aeeb2-de07-4877-9b98-3c10c34c086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ID column is unique : True\n"
     ]
    }
   ],
   "source": [
    "print(f\"The ID column is unique : {df['id'].is_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc34496-73a6-426a-a88f-74072ba27258",
   "metadata": {},
   "source": [
    "## Drop, drop, drop the columns!\n",
    "\n",
    "Here we define a `drop_columns` function to drop the unwanted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5f11af-918e-4fc4-917a-7ecb58b31640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df: pd.DataFrame, columns: List) -> pd.DataFrame:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): [description]\n",
    "        columns (List): [description]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy.drop(columns=columns, axis=1, inplace=False)\n",
    "    return df_copy.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4440797-68f0-4a50-93b4-38354fbc2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_columns(df, columns=config.unwanted_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce2a60-8abc-4813-879b-d50d34f423c9",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "Let us split the data types into a few unbrellas:\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<b> Categorical </b>\n",
    "    <li> <b>diagnosis</b>: The target variable diagnosis, although represented as string in the dataframe, should be categorical! This is because machines do not really like working with \"strings\" and prefer your type to be of \"numbers\". We will map them to 0 and 1, representing benign and malignant respectively. Since the target variable is just two unique values, we can use a simple map from pandas to do the job.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501f1f53-6ce9-452e-9710-5ea312f2b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\"B\" : 0, \"M\":1}\n",
    "df['diagnosis'] = df['diagnosis'].map(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71caeb0-5557-469f-806e-b05ef6449adf",
   "metadata": {},
   "source": [
    "We will make sure that our mapping is accurate by asserting the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea65c34-b99e-4f86-911a-de3e8ced920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df['diagnosis'].value_counts().to_dict()[0] == 357\n",
    "assert df['diagnosis'].value_counts().to_dict()[1] == 212"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f8de0-552b-449d-a289-f576774507bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b> Continuous </b>\n",
    "    <li> <b>predictors</b>: A preliminary look seems to suggest all our predictors are continuous.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c043e-4400-468c-ad95-f265ee57f5e0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "From the brief overview, there does not seem to be any Ordinal or Nominal Predictors. This suggest that we may not need to perform encoding in our preprocessing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d6e90-1353-422a-bb4a-576e40da60ce",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "We will use a simple, yet powerful function call to check on the summary statistics of our dataframe. We note to the readers that there are much more powerful libraries like [pandas-profiling](https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/) to give us an even more thorough summary, but for our purpose, we will use the good ol' `df.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1365b98d-44f5-483d-982f-8db32c216d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     0.372583    14.127292     19.289649       91.969033   654.889104   \n",
       "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
       "50%      0.000000    13.370000     18.840000       86.240000   551.100000   \n",
       "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ad572-002a-4ded-858b-18f070f98c17",
   "metadata": {},
   "source": [
    "The table does give us a good overview: for example, a brief glance give me the following observations:\n",
    "\n",
    "1. The features **do not seem to be of the same scale**. This is going to be a problem as some models do not perform well if your features are not on the same scale. A prime example is a KNN model with Euclidean Distance as the distance metric, the difference in range of different features will be amplified with the squared term, and the feature with wider range will dominate the one with smaller range. \n",
    "\n",
    "2. From our dataset it we see that **area_mean** is very large and there is likely to be a squared term (possibly from **radius_mean**), we can look into them later through EDA.\n",
    "\n",
    "Humans are more visual and that is why we still need EDA later to capture our attention on any anomaly from the dataset, and of course, if the dataset has many columns, then this summary statistics may even clog your progress if you were to read it line by line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045581dd-6f60-410b-862a-0403aa337225",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Missing Alert!</b> Although from our analysis, we did not see any missing data, it is always good to remind ourselves to check it. A simple function that does the job is as follows.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a22171c-ba0f-455f-9cad-7bd2b410de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_missing(df: pd.DataFrame, columns: List) -> pd.DataFrame:\n",
    "    \"\"\"A function to check for missing data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): [description]\n",
    "        columns (List): [description]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: [description]\n",
    "    \"\"\"\n",
    "    missing_dict = {\"missing num\": [], \"missing percentage\": []}\n",
    "    for col in columns:\n",
    "        num_missing = df[col].isnull().sum()\n",
    "        percentage_missing = num_missing / len(df)\n",
    "        missing_dict[\"missing num\"].append(num_missing)\n",
    "        missing_dict[\"missing percentage\"].append(percentage_missing)\n",
    "\n",
    "    missing_data_df = pd.DataFrame(index=columns, data=missing_dict)\n",
    "\n",
    "    return missing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54316fe5-bda2-4c92-b98e-197a64a97273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing num</th>\n",
       "      <th>missing percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                missing num  missing percentage\n",
       "diagnosis                 0                 0.0\n",
       "radius_mean               0                 0.0\n",
       "texture_mean              0                 0.0\n",
       "perimeter_mean            0                 0.0\n",
       "area_mean                 0                 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_df = report_missing(df, columns=df.columns)\n",
    "display(missing_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f31f16-99eb-499c-ae9a-2e6090e1cdae",
   "metadata": {},
   "source": [
    "## Save Data \n",
    "\n",
    "After Stage 1 is done, we saved the data to our processed folder, we name it `processed_data_stage_1.csv`, indicating that the data is processed after stage 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c1128a-9a4a-44ee-8e16-107a0f3fed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(config.processed_data_stage_1, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
