{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c7e7e9-33fc-49d1-b65a-a98cc993707e",
   "metadata": {},
   "source": [
    "## Imports, Config and Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e062f3e6-d7f2-4651-b7d2-181200b00873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "from typing import Dict, Union, Callable, OrderedDict\n",
    "import os, random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "59d99e81-3309-4367-8774-738dead6065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seed Number 1992\n"
     ]
    }
   ],
   "source": [
    "def seed_all(seed: int = 1992) -> None:\n",
    "    \"\"\"Seed all random number generators.\"\"\"\n",
    "    print(f\"Using Seed Number {seed}\")\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # set PYTHONHASHSEED env var at fixed value\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)  # pytorch (both CPU and CUDA)\n",
    "    np.random.seed(seed)  # for numpy pseudo-random generator\n",
    "    # set fixed value for python built-in pseudo-random generator\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "\n",
    "def seed_worker(_worker_id) -> None:\n",
    "    \"\"\"Seed a worker with the given ID.\"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "seed_all(seed=1992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e2d8059e-bc09-45be-948b-71d873b0f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c6c4f503-ce8a-4cbd-af17-e9be31796a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_pretrained_true = timm.create_model(model_name = \"resnet34\", pretrained=True, num_classes=10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb829e-6403-4596-a98a-d88793e30f90",
   "metadata": {},
   "source": [
    "## Toy Models\n",
    "\n",
    "I created two versions of the same model. The `Sequential` method has a more compact form, but often is more difficult to extract layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1cb064cc-1f9d-4385-82a5-ecc443ed77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cl1 = torch.nn.Linear(25, 60)\n",
    "        self.cl2 = torch.nn.Linear(60, 16)\n",
    "        self.fc1 = torch.nn.Linear(16, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x ([type]): [description]\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        x = torch.nn.ReLU()(self.cl1(x))\n",
    "        x = torch.nn.ReLU()(self.cl2(x))\n",
    "        x = torch.nn.ReLU()(self.fc1(x))\n",
    "        x = torch.nn.ReLU()(self.fc2(x))\n",
    "        x = torch.nn.LogSoftmax(dim=1)(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ToySequentialModel(torch.nn.Module):\n",
    "    # Create a sequential model pytorch same as ToyModel.\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = torch.nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"cl1\", torch.nn.Linear(25, 60)),\n",
    "                    (\"cl_relu1\", torch.nn.ReLU()),\n",
    "                    (\"cl2\", torch.nn.Linear(60, 16)),\n",
    "                    (\"cl_relu2\", torch.nn.ReLU()),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.head = torch.nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"fc1\", torch.nn.Linear(16, 120)),\n",
    "                    (\"fc_relu_1\", torch.nn.ReLU()),\n",
    "                    (\"fc2\", torch.nn.Linear(120, 84)),\n",
    "                    (\"fc_relu_2\", torch.nn.ReLU()),\n",
    "                    (\"fc3\", torch.nn.Linear(84, 10)),\n",
    "                    (\"fc_log_softmax\", torch.nn.LogSoftmax(dim=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x ([type]): [description]\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f8d3c-ecb8-4c8b-a7da-0f86746594aa",
   "metadata": {},
   "source": [
    "## Named Modules\n",
    "\n",
    "Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6a5903f3-d204-4282-bb94-96b785bd8f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "backbone\n",
      "backbone.cl1\n",
      "backbone.cl_relu1\n",
      "backbone.cl2\n",
      "backbone.cl_relu2\n",
      "head\n",
      "head.fc1\n",
      "head.fc_relu_1\n",
      "head.fc2\n",
      "head.fc_relu_2\n",
      "head.fc3\n",
      "head.fc_log_softmax\n"
     ]
    }
   ],
   "source": [
    "for name, layer in ToySequentialModel().named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d216aa-d95d-4723-b95f-23c88c1937dc",
   "metadata": {},
   "source": [
    "## Get Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1409cbb4-11c6-4836-a7de-ab5e81a56e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_layers(\n",
    "    model: Callable, layer_type: str = \"Conv2d\"\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Create a function that give me the convolutional layers of PyTorch model.\n",
    "\n",
    "    This function is created to be used in conjunction with Visualization of Feature Maps.\n",
    "\n",
    "    Args:\n",
    "        model (Union[torchvision.models, timm.models]): A PyTorch model.\n",
    "        layer_type (str): The type of layer to be extracted.\n",
    "\n",
    "    Returns:\n",
    "        conv_layers (Dict[str, str]): {\"layer1.0.conv1\": layer1.0.conv1, ...}\n",
    "\n",
    "    Example:\n",
    "        >>> resnet18_pretrained_true = timm.create_model(model_name = \"resnet34\", pretrained=True, num_classes=10).to(DEVICE)\n",
    "        >>> conv_layers = get_conv_layers(resnet18_pretrained_true, layer_type=\"Conv2d\")\n",
    "    \"\"\"\n",
    "\n",
    "    if layer_type == \"Conv2d\":\n",
    "        _layer_type = torch.nn.Conv2d\n",
    "    elif layer_type == \"Conv1d\":\n",
    "        _layer_type = torch.nn.Conv1d\n",
    "\n",
    "    conv_layers = {}\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, _layer_type):\n",
    "            conv_layers[name] = name\n",
    "    return conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c67d29cc-f40f-4991-98b9-21d62e4af708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv1': 'conv1', 'layer1.0.conv1': 'layer1.0.conv1', 'layer1.0.conv2': 'layer1.0.conv2', 'layer1.1.conv1': 'layer1.1.conv1', 'layer1.1.conv2': 'layer1.1.conv2', 'layer1.2.conv1': 'layer1.2.conv1', 'layer1.2.conv2': 'layer1.2.conv2', 'layer2.0.conv1': 'layer2.0.conv1', 'layer2.0.conv2': 'layer2.0.conv2', 'layer2.0.downsample.0': 'layer2.0.downsample.0', 'layer2.1.conv1': 'layer2.1.conv1', 'layer2.1.conv2': 'layer2.1.conv2', 'layer2.2.conv1': 'layer2.2.conv1', 'layer2.2.conv2': 'layer2.2.conv2', 'layer2.3.conv1': 'layer2.3.conv1', 'layer2.3.conv2': 'layer2.3.conv2', 'layer3.0.conv1': 'layer3.0.conv1', 'layer3.0.conv2': 'layer3.0.conv2', 'layer3.0.downsample.0': 'layer3.0.downsample.0', 'layer3.1.conv1': 'layer3.1.conv1', 'layer3.1.conv2': 'layer3.1.conv2', 'layer3.2.conv1': 'layer3.2.conv1', 'layer3.2.conv2': 'layer3.2.conv2', 'layer3.3.conv1': 'layer3.3.conv1', 'layer3.3.conv2': 'layer3.3.conv2', 'layer3.4.conv1': 'layer3.4.conv1', 'layer3.4.conv2': 'layer3.4.conv2', 'layer3.5.conv1': 'layer3.5.conv1', 'layer3.5.conv2': 'layer3.5.conv2', 'layer4.0.conv1': 'layer4.0.conv1', 'layer4.0.conv2': 'layer4.0.conv2', 'layer4.0.downsample.0': 'layer4.0.downsample.0', 'layer4.1.conv1': 'layer4.1.conv1', 'layer4.1.conv2': 'layer4.1.conv2', 'layer4.2.conv1': 'layer4.2.conv1', 'layer4.2.conv2': 'layer4.2.conv2'}\n"
     ]
    }
   ],
   "source": [
    ">>> resnet18_pretrained_true = timm.create_model(model_name = \"resnet34\", pretrained=True, num_classes=10).to(DEVICE)\n",
    ">>> conv_layers = get_conv_layers(resnet18_pretrained_true, layer_type=\"Conv2d\")\n",
    ">>> print(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4d207b8b-3baa-4f56-b33a-bf514822b4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head.fc2': tensor([[ 0.0697,  0.0544, -0.0157, -0.1059, -0.0464, -0.0090,  0.0532, -0.1273,\n",
      "         -0.0286, -0.0151,  0.0963,  0.2205,  0.0745, -0.0110, -0.1127, -0.0367,\n",
      "         -0.0681,  0.0463, -0.0833,  0.1288,  0.1058,  0.0976, -0.0251,  0.0980,\n",
      "         -0.0110,  0.1170, -0.0650,  0.2091, -0.1773,  0.0363, -0.1452,  0.0036,\n",
      "          0.0112, -0.0304, -0.0620, -0.0658, -0.0543,  0.0072,  0.0436,  0.0703,\n",
      "          0.0254, -0.0614,  0.0164, -0.1003, -0.0396,  0.0349,  0.0089, -0.1243,\n",
      "         -0.1037, -0.0491,  0.0627, -0.1347,  0.0010, -0.1290, -0.0280, -0.0344,\n",
      "          0.1487, -0.1764, -0.0233,  0.0082,  0.1270,  0.0368,  0.0103, -0.0929,\n",
      "          0.0038,  0.1346, -0.0688, -0.0437, -0.1205, -0.1596, -0.0240, -0.1001,\n",
      "         -0.0300, -0.1119,  0.0344, -0.1587,  0.0329, -0.0424,  0.0999,  0.0732,\n",
      "          0.1116,  0.0220, -0.0570,  0.0232]]), 'head.fc3': tensor([[ 0.0256, -0.0924,  0.0456,  0.0972,  0.0107,  0.0527,  0.0208,  0.0373,\n",
      "          0.0451,  0.0712]])}\n"
     ]
    }
   ],
   "source": [
    "activation = {}\n",
    "\n",
    "def get_intermediate_features(name: str) -> Callable:\n",
    "    \"\"\"Get the intermediate features of a model. Forward Hook.\n",
    "\n",
    "    This is using forward hook with reference https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5\n",
    "\n",
    "    Args:\n",
    "        name (str): name of the layer.\n",
    "\n",
    "    Returns:\n",
    "        Callable: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "\n",
    "    return hook\n",
    "\n",
    "\n",
    "# The below is testing the forward hook functionalities, especially getting intermediate features.\n",
    "# Note that both models are same organically but created differently.\n",
    "# Due to seeding issues, you can check whether they are the same output or not by running them separately.\n",
    "# We also used assertion to check that the output from model(x) is same as torch.nn.LogSoftmax(dim=1)(fc3_output)\n",
    "\n",
    "use_sequential_model = True\n",
    "x = torch.randn(1, 25)\n",
    "\n",
    "if not use_sequential_model:\n",
    "\n",
    "    model = ToyModel()\n",
    "\n",
    "    model.fc2.register_forward_hook(get_intermediate_features(\"fc2\"))\n",
    "    model.fc3.register_forward_hook(get_intermediate_features(\"fc3\"))\n",
    "    output = model(x)\n",
    "    print(activation)\n",
    "    fc2_output = activation[\"fc2\"]\n",
    "    fc3_output = activation[\"fc3\"]\n",
    "    # assert output and logsoftmax fc3_output are the same\n",
    "    assert torch.allclose(output, torch.nn.LogSoftmax(dim=1)(fc3_output))\n",
    "else:\n",
    "    sequential_model = ToySequentialModel()\n",
    "\n",
    "    # Do this if you want all, if not you can see below.\n",
    "    # for name, layer in sequential_model.named_modules():\n",
    "    #     layer.register_forward_hook(get_intermediate_features(name))\n",
    "    sequential_model.head.fc2.register_forward_hook(\n",
    "        get_intermediate_features(\"head.fc2\")\n",
    "    )\n",
    "    sequential_model.head.fc3.register_forward_hook(\n",
    "        get_intermediate_features(\"head.fc3\")\n",
    "    )\n",
    "    sequential_model_output = sequential_model(x)\n",
    "    print(activation)\n",
    "    fc2_output = activation[\"head.fc2\"]\n",
    "    fc3_output = activation[\"head.fc3\"]\n",
    "    assert torch.allclose(\n",
    "        sequential_model_output, torch.nn.LogSoftmax(dim=1)(fc3_output)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c71ceb-06f1-420a-8efc-f9d70848ab46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429e220-c6d8-4f66-9ed2-718387859384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
